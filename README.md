# Website_Information_Scraping

# Web Scraping Project

This project is designed to scrape various websites, extract relevant information, and store it in a structured format. The project includes multiple steps: setting up the environment, scraping the website, storing the scraped data, and cleaning the data.

## Table of Contents
1. [Installation](#installation)
2. [Usage](#usage)
    - [Step 1: Install Dependencies](#step-1-install-dependencies)
    - [Step 2: Scrape Website](#step-2-scrape-website)
    - [Step 3: Store Scraped Data](#step-3-store-scraped-data)
    - [Step 4: Clean Scraped Data](#step-4-clean-scraped-data)
    - [Step 5: Get Cleaned Data](#step-5-get-cleaned-data)
3. [Project Structure](#project-structure)
4. [Contributing](#contributing)
5. [License](#license)

## Installation

1. Clone the repository:

    ```sh
    git clone https://github.com/yourusername/web-scraping-project.git
    cd web-scraping-project
    ```

2. Create a virtual environment and activate it:

    ```sh
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```

3. Install the required packages:

    ```sh
    pip install -r 1_requirements.txt
    ```

## Usage

### Step 1: Install Dependencies

Ensure all necessary libraries are installed by using the `1_requirements.txt` file.

```sh
pip install -r 1_requirements.txt



python 2_Scraping_Website.py




python 4_Cleaning_Scraped_Data.py
